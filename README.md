# ğŸ¤– RAG Chatbot using Transformers & Streamlit

## ğŸ“Œ Project Overview
This project is a **Retrieval-Augmented Generation (RAG) chatbot** built during my **Data Science training**.

The application retrieves relevant information from an internal knowledge base using **sentence embeddings**, and then generates answers using a **large language model**.

---

## ğŸ§  How It Works
1. User enters a question
2. Question is converted into an embedding
3. Most relevant documents are retrieved using cosine similarity
4. Retrieved context is passed to an LLM
5. LLM generates an answer grounded in retrieved context

---

## ğŸ”§ Tech Stack
- Python
- Streamlit
- Sentence Transformers
- Hugging Face Transformers
- TinyLlama (Chat Model)
- NumPy

---

## ğŸš€ Features
- Retrieval-Augmented Generation
- Embedding-based semantic search
- Chat-style Streamlit UI
- Cached models for faster performance

---

## â–¶ï¸ How to Run
```bash
streamlit run app.py
```
## ğŸ“š Sample Knowledge Base
- RAG concepts
- LangChain basics
- Embeddings
- Transformers
- Vector databases

## ğŸ“ Learning Outcome
- Built a RAG pipeline from scratch
- Understood embeddings and retrieval
- Implemented LLM-based generation
- Learned how to deploy GenAI apps using Streamlit

## ğŸ‘¤ Author

Shaik Maherin<br>
Computer Science Student<br>
Data Science & Full Stack Development<br>
